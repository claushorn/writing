---
layout: page
title: "About"
permalink: /about/
---

Welcome to **AI Interpretability and Scientific Discovery**, a blog dedicated to advancing the frontiers of **artificial intelligence** in scientific discovery. Here, we explore the intersection of **mechanistic interpretability**, **neuro-symbolic reasoning**, and **practical AI tools** for accelerating breakthroughs in the natural sciences.

I am Claus Horn, a scientist with a background in **particle physics** and over a decade of experience in **machine learning research**. My work bridges fundamental research in physics, computational biology, and AI, driven by a commitment to building **transparent, interpretable models** that enhance trust and foster deeper insights into complex systems.

This blog is a platform to:
- **Demystify AI models** and expose their inner workings.
- **Connect AI with domain knowledge** in physics, biology, and beyond.
- **Promote open, rigorous science** that integrates symbolic and neural approaches.

Whether you’re a researcher, practitioner, or simply curious about how AI can accelerate scientific discovery, I invite you to join this journey.

---

## Contact

If you’d like to collaborate, share insights, or discuss AI interpretability challenges, please get in touch:

- Email: [claus.horn@yale.edu](mailto:claus.horn@yale.edu)
- GitHub: [claushorn](https://github.com/claushorn)
- LinkedIn: [aiscientist](https://www.linkedin.com/in/aiscientist/)

---

*Let’s build the future of AI for science — responsibly, rigorously, and transparently.*

